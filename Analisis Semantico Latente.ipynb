{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Semántico Latente\n",
    "En este cuaderno se realizará la implementación del modelo de Analisis Semántico Latente (LSA) para dos documentos de prueba dentro del corpus.\n",
    "\n",
    "Esta etapa esta compuesta de las siguientes fases:\n",
    "1. Cargar datos.\n",
    "2. Tokenizar por frases el corpus.\n",
    "3. Aplicar el preprocesamiento al nuevo corpus.\n",
    "4. Crear diccionarios para relacionar frases e identificadores.\n",
    "5. Construir la matriz de A del Análisis Semántico Latente.\n",
    "6. Aplicar la técnica de Análisis Semántico Latente.\n",
    "7. Generación de resumen\n",
    "8. Evaluar el resumen obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar elementos necesarios de las librerías\n",
    "import os, shutil, re, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones auxiliares\n",
    "\n",
    "def tokenize_sentence(path, file_name):\n",
    "    #Retorna un documento tokenizado por frases\n",
    "    doc = []\n",
    "    text = PlaintextCorpusReader(path, file_name)\n",
    "    paragraphs = text.paras()\n",
    "    for paragraph in paragraphs:\n",
    "        for sentence in paragraph:\n",
    "            low, i = 0,0\n",
    "            while i < len(sentence):\n",
    "                token = sentence[i].split('.')\n",
    "                if len(token)-1:\n",
    "                    doc.append(sentence[low:i])\n",
    "                    low=i+1\n",
    "                    i+=2\n",
    "                else:\n",
    "                    i+=1\n",
    "            if low!=i-1:\n",
    "                doc.append(sentence[low:i])\n",
    "    return doc\n",
    "\n",
    "def preprocess(doc, stopwords, stemmer):\n",
    "    #Aplica el preprocesamiento establecido\n",
    "    #Adicionalmente, retorna el documento original sin las filas vacías por el preprocesamiento \n",
    "    doc_preprocesed, doc_reduced = [], []\n",
    "    for original_sentence in doc:\n",
    "        preprocessed_sentence = []\n",
    "        for token in original_sentence:\n",
    "            if stemmer.stem(token) not in stopwords:\n",
    "                preprocessed_sentence.append(stemmer.stem(token))\n",
    "        if len(preprocessed_sentence) and preprocessed_sentence not in doc_preprocesed:\n",
    "            doc_preprocesed.append(preprocessed_sentence)\n",
    "            doc_reduced.append(original_sentence)\n",
    "    return doc_preprocesed, doc_reduced\n",
    "\n",
    "def get_dictionaries(doc):\n",
    "    #Retorna un par de diccionarios que relacionan una frase con un id, y un id con una frase.\n",
    "    sentence2id, id2sentence = {},{}\n",
    "    n_sentences = len(doc)\n",
    "    for i in range(n_sentences):\n",
    "        sentence = ' '.join(doc[i])\n",
    "        if sentence not in sentence2id:\n",
    "            sentence2id[sentence] = i\n",
    "            id2sentence[i] = sentence\n",
    "    return sentence2id, id2sentence\n",
    "\n",
    "def getid2token(token2id):\n",
    "    #Retorna un diccionario de tokens a id, a partir de un diccionario de id a tokens\n",
    "    id2token ={}\n",
    "    for k,v in token2id.items():\n",
    "        id2token[v] = k\n",
    "    return id2token\n",
    "\n",
    "def build_A_Matrix(document, tf_idf, token2id, doc_id):\n",
    "    #Construye la matriz A que recibe el modelo de LSA como entrada\n",
    "    data,row_index,col_index = [],[],[]\n",
    "    tf_idf = tf_idf.toarray()\n",
    "    n,m = len(document), len(token2id)\n",
    "    for i in range(n):\n",
    "        sentence = document[i]\n",
    "        j = 0\n",
    "        for token in sentence:\n",
    "            if token in token2id and tf_idf[doc_id,token2id[token]] != 0:\n",
    "                if (j==0) or (j>0 and token2id[token] not in col_index[-j:]):\n",
    "                    value = tf_idf[doc_id,token2id[token]]\n",
    "                    tf_idf_value = value\n",
    "                    data.append(tf_idf_value)\n",
    "                    row_index.append(i)\n",
    "                    col_index.append(token2id[token])\n",
    "                    j+=1\n",
    "    data = np.array(data)\n",
    "    row_index = np.array(row_index)\n",
    "    col_index = np.array(col_index)\n",
    "    A_matrix = csr_matrix((data,(row_index,col_index)),shape=(n, m),dtype=np.float64)\n",
    "    return A_matrix\n",
    "\n",
    "def generate_summary(lsa, n_sentences, sentence2id):\n",
    "    #Genera un resumen con n_sentences frases\n",
    "    total_sentences = lsa.shape[0]\n",
    "    assert n_sentences < total_sentences\n",
    "    columns = [\"topic {}\".format(i) for i in range(n_sentences)]\n",
    "    df = pd.DataFrame(lsa,columns=columns)\n",
    "    df['sentence'] = sentence2id.keys()\n",
    "    summary = []\n",
    "    for i in range(n_sentences):\n",
    "        df = df.sort_values(by='topic {}'.format(i), ascending = False)\n",
    "        j = 0\n",
    "        while j < total_sentences:\n",
    "            sentence = df.iloc[j]['sentence']\n",
    "            if sentence not in summary:\n",
    "                summary.append(sentence)\n",
    "                j=total_sentences\n",
    "            else:\n",
    "                j+=1\n",
    "    return summary\n",
    "\n",
    "def read_reference(path, filename):\n",
    "    text = PlaintextCorpusReader(path, filename)\n",
    "    text = text.paras()\n",
    "    flat = []\n",
    "    for sentences in text:\n",
    "        for sentence in sentences:\n",
    "            flat_sentence = ' '.join(sentence)\n",
    "            flat.append(flat_sentence)\n",
    "    reference = ' '.join(flat)\n",
    "    return reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1. Cargar datos.\n",
    "En esta fase se cargarán datos obtenidos durante el preprocesamientoy que utilizaremos para obtener el modelo de LSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el modelo de tf-idf obtenido en preprocesamiento.\n",
    "filename = 'tf-idf_model.pkl'\n",
    "tf_idf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Cargar la matriz de tf-idf obtenido en preprocesamiento.\n",
    "filename = 'tf-idf_matrix.pkl'\n",
    "tf_idf_matrix = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Cargar la matriz de tf-idf obtenido en preprocesamiento.\n",
    "filename = 'stopwords.pkl'\n",
    "stopwords = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2. Tokenizar las frases del corpus.\n",
    "En esta fase se tokenizará por el corpus por frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"D:/Documents/Documentos Universidad/Noveno/Proyecto de grado/textos\"\n",
    "stemmer = SpanishStemmer()\n",
    "corpus = []\n",
    "referencias = ['azure-pagos.txt','chrome-privacidad.txt','colboletos.txt','gdo-privacidad.txt',\n",
    "               'mozilla-privacidad.txt','nintendo-condiciones.txt','netflix-condiciones.txt',\n",
    "               'segurosbolivar-privacidad.txt','whatsApp-privacidad.txt']\n",
    "n_referencias = len(referencias)\n",
    "\n",
    "for doc in referencias:\n",
    "    documento = tokenize_sentence(ruta, doc)\n",
    "    corpus.append(documento)\n",
    "\n",
    "#colboletos = tokenize_sentence(ruta,'colboletos.txt')\n",
    "#mozilla = tokenize_sentence(ruta,'mozilla-privacidad.txt')\n",
    "#nintendo = tokenize_sentence(ruta,'nintendo-condiciones.txt')\n",
    "bolivar = tokenize_sentence(ruta,'segurosbolivar-privacidad.txt')\n",
    "#whatsapp = tokenize_sentence(ruta,'whatsApp-privacidad.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 3. Aplicar el preprocesamiento al nuevo corpus.\n",
    "En esta fase se aplicará el preprocesamiento establecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_preprocesado = []\n",
    "for i in range(n_referencias):\n",
    "    doc_preprocesado, corpus[i] = preprocess(corpus[i], stopwords, stemmer)\n",
    "    corpus_preprocesado.append(doc_preprocesado)\n",
    "\n",
    "bolivar_preprocesado, bolivar = preprocess(bolivar, stopwords, stemmer)\n",
    "#mozilla_preprocesado, mozilla = preprocess(mozilla, stopwords, stemmer)\n",
    "#colboletos_preprocesado, colboletos = preprocess(colboletos, stopwords, stemmer)\n",
    "#nintendo_preprocesado, nintendo = preprocess(nintendo, stopwords, stemmer)\n",
    "#whatsapp_preprocesado, whatsapp = preprocess(whatsapp, stopwords, stemmer)\n",
    "#bolivar = corpus[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 4. Crear diccionarios para relacionar frases e identificadores.\n",
    "Con el fin de obtener un resumen luego de aplicar la técnica de LSA, se necesita relacionar una frase con un identificador único. Esta fase cumple con dicho objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase2id, id2frase = [],[]\n",
    "\n",
    "for i in range(n_referencias):\n",
    "    f2id, id2f = get_dictionaries(corpus[i])\n",
    "    frase2id.append(f2id)\n",
    "    id2frase.append(id2f)\n",
    "\n",
    "#frase2id_colboletos, id2frase_colboletos = get_dictionaries(colboletos)\n",
    "#frase2id_mozilla, id2frase_mozilla = get_dictionaries(mozilla)\n",
    "#frase2id_nintendo, id2frase_nintendo = get_dictionaries(nintendo)\n",
    "frase2id_bolivar, id2frase_bolivar = get_dictionaries(bolivar)\n",
    "#frase2id_whatsapp, id2frase_whatsapp = get_dictionaries(whatsapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 5. Construir la matriz de A del Análisis Semántico Latente.\n",
    "Hasta el momento, ya tenemos una lista de frases preprocesadas, ahora lo siguiente que tenemos que hacer es construir una matriz A de NxM, con N frases y M tokens. Para esto nos apoyaremos en el TF-IDF del preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diccionario que relaciona tokens con un identificador único\n",
    "token2id = tf_idf.vocabulary_\n",
    "\n",
    "#Lista de textos dentro del corpus\n",
    "textos = os.listdir(ruta)\n",
    "\n",
    "matriz_A_corpus = []\n",
    "for i in range(n_referencias):\n",
    "    matriz_A_doc = build_A_Matrix(corpus_preprocesado[i], tf_idf_matrix, token2id, textos.index(referencias[i]))\n",
    "    matriz_A_corpus.append(matriz_A_doc)\n",
    "\n",
    "#matriz_A_colboletos = build_A_Matrix(colboletos_preprocesado, tf_idf_matrix, token2id, textos.index('colboletos.txt'))\n",
    "#matriz_A_mozilla = build_A_Matrix(mozilla_preprocesado, tf_idf_matrix, token2id, textos.index('mozilla-privacidad.txt'))\n",
    "#matriz_A_nintendo = build_A_Matrix(nintendo_preprocesado, tf_idf_matrix, token2id, textos.index('nintendo-condiciones.txt'))\n",
    "matriz_A_bolivar = build_A_Matrix(bolivar_preprocesado, tf_idf_matrix, token2id, textos.index('segurosbolivar-privacidad.txt'))\n",
    "#matriz_A_whatsapp = build_A_Matrix(whatsapp_preprocesado, tf_idf_matrix, token2id, textos.index('whatsApp-privacidad.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 6. Aplicar la técnica de Análisis Semántico Latente.\n",
    "Una vez construida la matriz A, se utilizará la técnica de LSA para obtener una matriz de MxK, con M frases y K temas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "#Instancia un modelo de LSA\n",
    "lsa_model = TruncatedSVD(n_components=k)\n",
    "\n",
    "#Aplica el LSA a la matriz tf-idf\n",
    "lsa_corpus = []\n",
    "\n",
    "for i in range(n_referencias):\n",
    "    lsa_doc = lsa_model.fit_transform(matriz_A_corpus[i])\n",
    "    lsa_corpus.append(lsa_doc)\n",
    "\n",
    "#lsa_colboletos = lsa_model.fit_transform(matriz_A_colboletos)\n",
    "#lsa_mozilla = lsa_model.fit_transform(matriz_A_mozilla)\n",
    "#lsa_nintendo = lsa_model.fit_transform(matriz_A_nintendo)\n",
    "lsa_bolivar = lsa_model.fit_transform(matriz_A_bolivar)\n",
    "#lsa_whatsapp = lsa_model.fit_transform(matriz_A_whatsapp)\n",
    "#matriz_A_bolivar=matriz_A_corpus[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensión de la matriz de Seguros Bolivar\n",
    "#lsa_bolivar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensión de la matriz de Mozilla\n",
    "#lsa_mozilla.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 7. Generación del resumen\n",
    "A partir del modelo de LSA obtenido en la fase anterior, se genera un resúmen escogiendo una frase por cada tema obtenido dentro del modelo de LSA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure-pagos.txt\n",
      "['Durante el Período de Vigencia de la Suscripción , los precios de los Servicios Online no aumentarán , en cuanto a la Suscripción , con relación a los publicados en el Portal en el momento en que la Suscripción entró en vigor o se renovó , salvo si los precios se identificaron como temporales en los Detalles de la Oferta o para Versiones Preliminares de Productos que no son de Microsoft', '( iii ) Para las Ofertas de Consumo , la Suscripción se renovará automáticamente para períodos de vigencia adicionales de un mes hasta que finalice la Suscripción', 'Usted es responsable del uso que haga el tercero de los Servicios de Microsoft Azure , de acuerdo con los términos de este contrato', 'Usted podrá utilizar el Producto solo de acuerdo con los términos de este contrato', 'Este Contrato Microsoft Online Subscription se celebra entre la entidad que usted representa o , en caso de que no designe ninguna entidad en relación con una adquisición o renovación de Suscripción , usted individualmente (\" usted \") y Microsoft Corporation (\" Microsoft \", \" nosotros']\n",
      "\n",
      "chrome-privacidad.txt\n",
      "['Sincronización : Cuando accede al navegador Chrome o una Chromebook y sincroniza su Cuenta de Google , su información personal se guarda en su Cuenta de Google , en los servidores de Google , para que pueda acceder a ella cuando ingresa en Chrome y lo sincroniza en otras computadoras y dispositivos', 'Con ella , se envía y recibe información sobre sitios web sospechosos entre el navegador en uso y los servidores de Google', 'Información básica sobre el historial de navegación , como URL , texto de páginas almacenadas en caché o direcciones IP de páginas vinculadas de los sitios web que visita Instantáneas de las páginas que visita Registros de descargas , aunque los archivos que descarga seguirán almacenándose en otra ubicación de la computadora o el dispositivo', 'La información que reciben otros operadores de sitios web y los desarrolladores de complementos , incluidas las cookies , está sujeta a las políticas de privacidad de esos sitios web', 'Cookies o datos de los sitios web que visita']\n",
      "\n",
      "colboletos.txt\n",
      "['DEBERES : COLBOLETOS está obligada a cumplir los deberes que impone la normatividad aplicable respecto al tratamiento de datos personales , cuando actúe : I ) Como Responsables del tratamiento : ( a ) Garantizar al Titular el ejercicio del derecho de hábeas data ; ( b ) Solicitar y conservar , en las condiciones aquí previstas , copia de la respectiva autorización otorgada por el titular ; ( c ) Informar claramente al titular sobre la finalidad de la recolección y los derechos que le asisten en virtud de la autorización otorgada y el uso que se le dará a sus datos personales ; ( d ) Conservar la información bajo condiciones de seguridad que impidan su adulteración , pérdida , consulta , uso o acceso no autorizado o fraudulento ; ( e ) Actualizar la información de los titulares y rectificarla cuando sea incorrecta ; ( f ) Tramitar las consultas y reclamos formulados por los titulares de la información ; ( g ) Procurar que los principios de veracidad , calidad , seguridad y confidencialidad en los términos establecidos en la siguiente política ; ( h ) Exigir el respeto a las condiciones de seguridad y privacidad de la información del Titular e Informar a la autoridad de protección de datos cuando se presenten violación a la seguridad de la misma y cuando existan riesgos en la administración de la información ; ( i ) Cumplir las instrucciones y requerimientos que imparta la Superintendencia de Industria y Comercio', 'II ) Como Encargados del tratamiento de datos personales , cuando llegare a efectuar el tratamiento en nombre de otra entidad u organización ( Responsable del tratamiento ) deberá : a ) Garantizar al Titular , el ejercicio del derecho de hábeas data ; b ) Conservar la información bajo las condiciones de seguridad necesarias para impedir su adulteración , pérdida , consulta , uso o acceso no autorizado o fraudulento ; c ) Realizar oportunamente la actualización , rectificación o supresión de los datos en los términos de la presente ley ; la actualización de la información reportada por los Responsables del Tratamiento , se deberá efectuar dentro de los cinco ( 5 ) días hábiles contados a partir de su recibo ; d ) Tramitar las consultas y los reclamos formulados por los Titulares en los términos señalados en la legislación aplicable ; e ) Registrar en la base de datos las leyenda “ reclamo en trámite ” en la forma en que se regula en la normatividad aplicable ; f ) Insertar en la base de datos la leyenda “ información en discusión judicial ” una vez notificado por parte de la autoridad competente sobre procesos judiciales relacionados con la calidad del dato personal ; g ) Abstenerse de circular información que esté siendo controvertida por el Titular y cuyo bloqueo haya sido ordenado por la Superintendencia de Industria y Comercio ; h ) Permitir el acceso a la información únicamente a las personas que pueden tener acceso a ella ; i ) Informar a la Superintendencia de Industria y Comercio cuando se presenten violaciones a los códigos de seguridad y existan riesgos en la administración de la información de los Titulares ; j ) Cumplir las instrucciones y requerimientos que imparta la Superintendencia de Industria y Comercio', 'SOLICITUD DE AUTORIZACIÓN AL TITULAR DEL DATO PERSONAL : Previamente y / o al momento de efectuar la recolección de datos personales , COLBOLETOS solicitará autorización al titular del dato , para su recolección y tratamiento , comunicando la finalidad de su obtención , a través de medios técnicos automatizados , orales o escritos , que permitan conservar prueba de la autorización y / o de la conducta inequívoca descrita en el artículo 7 del Decreto 1377 de 2013', 'Tenga en cuenta que en algunos casos COLBOLETOS extrae la información de los registros recogidos para obtener datos colectivos', 'El titular del dato personal o quien lo represente podrá allegar su petición , queja o reclamo de lunes a viernes de 8 : 00 a']\n",
      "\n",
      "gdo-privacidad.txt\n",
      "[': Confrontar la información personal entregada con bases de datos públicas , centrales y sistemas de prevención de riesgo , compañías especializadas , referencias y contactos en aras de realizar actividades de confirmación para prestar de manera adecuada los servicios públicos domiciliarios ofrecidos por GASES DE OCCIDENTE S', '; desarrollar estrategias de expansión de mercado , estudios de políticas tendientes a la ampliación de demanda , realización de campañas , actividades comerciales y de mercadeo , inteligencia de negocios y analítica de datos a través de tecnologías Big Data ; tratar sus datos con el fin de llevar a cabo estudios económicos de demanda del servicio y actividades de fidelización , determinación de niveles de satisfacción , envío de comunicaciones comerciales ; compartir sus datos personales que reposan en el catastro de suscriptores tales como nombre , número de teléfono fijo , personal o laboral , número de móvil personal o laboral y dirección de prestación del servicio público domiciliario con otras empresas de servicios públicos domiciliarios , con el fin de mantener actualizados nuestros registros y poder prestar un mejor servicio ; éstas actividades podrán desarrollarse por medio de redes sociales ( RRSS ), servicios de mensajería instantánea o cualquier medio de comunicación físico o electrónico , conocido o por conocerse', '; cumplir con las obligaciones legales relativas a la prestación del servicio público de gas domiciliario de acuerdo a lo establecido en la Ley 142 de 1994 y el contrato de condiciones uniformes establecido por GASES DE OCCIDENTE S', 'TRATAMIENTOS Y FINALIDADES APLICADAS A LOS DATOS DE CARÁCTER PERSONAL DE NUESTROS CLIENTES Y PROSPECTOS DE SERVICIO PÚBLICO DE GAS DOMICILIARIO', 'Los datos de nuestros clientes de servicios de financiación no bancaria los cuales son capturados o recolectados mediante formularios físicos o electrónicos , serán almacenados , usados , procesados , suprimidos , transmitidos y / o transferidos a terceros para aplicar las finalidades que se determinan a continuación : Confrontar la información personal entregada con bases de datos públicas , centrales y sistemas de prevención de riesgo , compañías especializadas , referencias y contactos en aras de realizar actividades de confirmación ; asignar cupos de crédito brilla de acuerdo los requisitos establecidos por la compañía ; acreditar las actividades en relación a su condición de usuario de los servicios de financiación no bancaria ofrecidos por GASES DE OCCIDENTE S']\n",
      "\n",
      "mozilla-privacidad.txt\n",
      "['Política de Privacidad de Mozilla 9 de septiembre de 2020 ¿ Qué queremos decir con \" informaciones personales \"?', 'Mozilla Corporation Attn : Mozilla - Privacy 2 Harrison St', 'Haz clic aquí para solicitar acceso a los datos personales', 'Eventualmente divulgamos informaciones para mejorar nuestros productos y promover una Internet abierta , pero cuando lo hacemos , excluimos sus informaciones personales e intentamos divulgarlas de forma de minimizar el riesgo de identificación de los usuarios', 'Sus informaciones sólo son divulgadas de esa manera cuando creemos de buena fe que se hace necesario para proteger los derechos , la propiedad o la seguridad del usuario en cuestión , de nuestros otros usuarios , de Mozilla o del público']\n",
      "\n",
      "nintendo-condiciones.txt\n",
      "['Si bien Nintendo no tiene obligación de analizar , editar ni supervisar el Contenido del usuario publicado en los Servicios , Nintendo se reserva el derecho , y tiene la absoluta discreción , de acceder , usar , supervisar , divulgar o preservar información asociada con su uso de los Servicios , incluido , entre otras cosas , el Contenido del usuario , o información que Nintendo obtenga sobre usted mediante su uso de los Servicios , cuando Nintendo tenga la creencia de buena fe de que hacerlo es necesario ( a ) para cumplir con la ley aplicable o responder a un proceso legal de autoridades competentes ; ( b ) para hacer cumplir estas Condiciones o proteger los derechos ( como derechos de propiedad ) de Nintendo o sus usuarios ; ( c ) para ayudar a evitar una muerte o una lesión física grave de cualquier persona ; o ( d ) para evitar actividades potencialmente ilegales u ofensivas', 'Al enviar o publicar Contenido del usuario en los Servicios , usted expresa y garantiza que : ( a ) dicho Contenido del usuario no es confidencial ; ( b ) usted tiene titularidad y control sobre los derechos del contenido que publica , o , de algún otro modo , tiene los derechos necesarios para publicar dicho contenido en los Servicios ; ( c ) el Contenido del usuario es correcto y no es engañoso o dañino de ninguna forma ; y ( d ) el Contenido del usuario , y su uso y publicación de este en relación con los Servicios , no violan ni violarán estas Condiciones ni ninguna ley , norma o reglamentación aplicables', 'Cuando usted participa en las Áreas interactivas , comprende que determinado Contenido del usuario puede exhibirse públicamente o a usuarios selectos', 'Si está obligado a indemnizarnos , tendremos derecho , a discreción propia y sin restricción , de controlar cualquier demanda o procedimiento y determinar si deseamos realizar un acuerdo y , de ser así , con qué condiciones', 'Usted acepta que podremos suspender o cancelar su derecho de acceso a nuestros Servicios en cualquier momento y por cualquier motivo , sin aviso y sin obligaciones o responsabilidades hacia usted']\n",
      "\n",
      "netflix-condiciones.txt\n",
      "['Si se suscribió a Netflix usando su cuenta con un tercero como Forma de pago , puede encontrar la información sobre la facturación de su membresía de Netflix en su cuenta correspondiente del servicio del tercero', 'Podemos autorizar su Forma de pago antes del cobro relacionado con la membresía o el servicio a través de varios métodos , e incluso autorizarla para que dure aproximadamente un mes de servicio a partir de su registro', 'Podrá encontrar la información específica sobre su membresía de Netflix visitando nuestro sitio web y haciendo clic en el vínculo “ Cuenta ”, disponible en la parte superior de las páginas bajo su nombre de perfil', 'El miembro que creó la cuenta de Netflix y al que se le facturan los cargos a través de su Forma de pago ( el “ Titular de la cuenta ”) es responsable de cualquier actividad que ocurra en la cuenta de Netflix', 'Se aplican restricciones , incluidas las restricciones a la cantidad de Títulos offline por cada cuenta , la cantidad máxima de dispositivos que pueden contener Títulos offline , el período en el cual deberá comenzar a ver los Títulos offline y cuánto tiempo permanecerán accesibles los Títulos offline']\n",
      "\n",
      "segurosbolivar-privacidad.txt\n",
      "['LAS COMPAÑÍAS han identificado los datos que administran , así como las actividades que desarrollan con dichos datos , en particular su recepción , conservación , disposición para los fines propios del contrato y desarrollo de actividades complementarias referidas a la promoción y el mercadeo de sus productos y servicios , así como los ofrecidos por las Compañías que hacen parte del Grupo Bolívar , al cual éstas pertenecen y así lo han indicado en las Políticas del Tratamiento disponibles para su consulta en la página web www', 'LAS COMPAÑÍAS hacen parte del Grupo Bolívar , que tiene como matriz a Grupo Bolívar S', 'Declaro que , con base en dicho conocimiento , autorizo para que LAS COMPAÑÍAS compartan con dichas empresas y entidades la información personal de contacto y la que sea relevante para las finalidades aquí previstas , que he suministrado', 'Finalidades previstas para los datos obtenidos de candidatos , empleados y proveedores :', 'Solicitar prueba de la autorización otorgada al Responsable del Tratamiento salvo cuando expresamente se exceptúe como requisito para el Tratamiento , de conformidad con lo previsto en el artículo 10 de la presente ley']\n",
      "\n",
      "whatsApp-privacidad.txt\n",
      "['Si eliminas tu cuenta de WhatsApp , los mensajes no entregados se eliminarán de nuestros servidores , así como cualquier otra información que ya no necesitemos para operar y proporcionarte nuestros Servicios', 'De hecho , Facebook no usará tus mensajes de WhatsApp para ningún otro propósito que no sea el de asistirnos en operar y proveer nuestros Servicios', 'Nada de lo que compartes en WhatsApp -- incluyendo tus mensajes , fotos , e información de la cuenta -- será compartido en Facebook , o en la familia de aplicaciones de Facebook , para que otros los vean', 'Si un mensaje no se puede entregar de inmediato ( por ejemplo , si no tienes conexión a internet ), podemos conservarlo en nuestros servidores durante un plazo máximo de 30 días mientras intentamos entregarlo', 'Volver al comienzo Ley de Privacidad del Consumidor de California']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resumenes = []\n",
    "for i in range(n_referencias):\n",
    "    print(referencias[i])\n",
    "    resumen_doc = generate_summary(lsa_corpus[i],k,frase2id[i])\n",
    "    print(resumen_doc)\n",
    "    print()\n",
    "    resumenes.append(resumen_doc)\n",
    "\n",
    "#resumen_bolivar = generate_summary(lsa_bolivar,k,frase2id_bolivar)\n",
    "#resumen_bolivar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar puntajes ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_referencia = \"D:/Documents/Documentos Universidad/Noveno/Proyecto de grado/referencias\"\n",
    "\n",
    "resumenes_referencia = []\n",
    "\n",
    "for doc in referencias:\n",
    "    referencia_doc = read_reference(ruta_referencia, doc)\n",
    "    resumenes_referencia.append(referencia_doc)\n",
    "\n",
    "#referencia_bolivar = read_reference(ruta_referencia, 'segurosbolivar-privacidad.txt')\n",
    "\n",
    "#Castea cada resumen a un solo string\n",
    "resumenes = [' '.join(doc) for doc in resumenes]\n",
    "\n",
    "#resumen_bolivar = ' '.join(resumen_bolivar)\n",
    "rouge = Rouge(metrics=[\"rouge-1\", \"rouge-l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure-pagos.txt\n",
      "[{'rouge-1': {'f': 0.30225080071817106, 'p': 0.7747252747252747, 'r': 0.1877496671105193}, 'rouge-l': {'f': 0.22281166731771848, 'p': 0.4421052631578947, 'r': 0.14893617021276595}}]\n",
      "\n",
      "chrome-privacidad.txt\n",
      "[{'rouge-1': {'f': 0.31685392952162617, 'p': 0.8392857142857143, 'r': 0.19529085872576177}, 'rouge-l': {'f': 0.3106266993233301, 'p': 0.6404494382022472, 'r': 0.20503597122302158}}]\n",
      "\n",
      "colboletos.txt\n",
      "[{'rouge-1': {'f': 0.4121739081977467, 'p': 0.3505917159763314, 'r': 0.5}, 'rouge-l': {'f': 0.17635270041084183, 'p': 0.17670682730923695, 'r': 0.176}}]\n",
      "\n",
      "gdo-privacidad.txt\n",
      "[{'rouge-1': {'f': 0.5276461248188996, 'p': 0.42710997442455245, 'r': 0.6900826446280992}, 'rouge-l': {'f': 0.4058823480249136, 'p': 0.359375, 'r': 0.46621621621621623}}]\n",
      "\n",
      "mozilla-privacidad.txt\n",
      "[{'rouge-1': {'f': 0.624113470322167, 'p': 0.7521367521367521, 'r': 0.5333333333333333}, 'rouge-l': {'f': 0.6304347776465029, 'p': 0.6904761904761905, 'r': 0.58}}]\n",
      "\n",
      "nintendo-condiciones.txt\n",
      "[{'rouge-1': {'f': 0.47685834002820787, 'p': 0.4594594594594595, 'r': 0.4956268221574344}, 'rouge-l': {'f': 0.1971014442804454, 'p': 0.20359281437125748, 'r': 0.19101123595505617}}]\n",
      "\n",
      "netflix-condiciones.txt\n",
      "[{'rouge-1': {'f': 0.3809523768340174, 'p': 0.6567164179104478, 'r': 0.2682926829268293}, 'rouge-l': {'f': 0.25806451184458346, 'p': 0.41509433962264153, 'r': 0.18723404255319148}}]\n",
      "\n",
      "segurosbolivar-privacidad.txt\n",
      "[{'rouge-1': {'f': 0.323450129773832, 'p': 0.3157894736842105, 'r': 0.3314917127071823}, 'rouge-l': {'f': 0.205607471637261, 'p': 0.20952380952380953, 'r': 0.2018348623853211}}]\n",
      "\n",
      "whatsApp-privacidad.txt\n",
      "[{'rouge-1': {'f': 0.33910034231438807, 'p': 0.6901408450704225, 'r': 0.22477064220183487}, 'rouge-l': {'f': 0.3043478217433313, 'p': 0.4772727272727273, 'r': 0.22340425531914893}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_referencias):\n",
    "    print(referencias[i])\n",
    "    print(rouge.get_scores(resumenes[i],resumenes_referencia[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
