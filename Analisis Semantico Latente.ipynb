{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Semántico Latente\n",
    "En este cuaderno se realizará la implementación del modelo de Analisis Semántico Latente (LSA) para dos documentos de prueba dentro del corpus.\n",
    "\n",
    "Esta etapa esta compuesta de las siguientes fases:\n",
    "1. Cargar datos.\n",
    "2. Tokenizar por frases el corpus.\n",
    "3. Aplicar el preprocesamiento al nuevo corpus.\n",
    "4. Crear diccionarios para relacionar frases e identificadores.\n",
    "5. Construir la matriz de A del Análisis Semántico Latente.\n",
    "6. Aplicar la técnica de Análisis Semántico Latente.\n",
    "7. Generación de resumen\n",
    "8. Evaluar el resumen obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar elementos necesarios de las librerías\n",
    "import os, shutil, re, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones auxiliares\n",
    "\n",
    "def tokenize_sentence(path, file_name):\n",
    "    #Retorna un documento tokenizado por frases\n",
    "    doc = []\n",
    "    text = PlaintextCorpusReader(path, file_name)\n",
    "    paragraphs = text.paras()\n",
    "    for paragraph in paragraphs:\n",
    "        for sentence in paragraph:\n",
    "            low, i = 0,0\n",
    "            while i < len(sentence):\n",
    "                token = sentence[i].split('.')\n",
    "                if len(token)-1:\n",
    "                    doc.append(sentence[low:i])\n",
    "                    low=i+1\n",
    "                    i+=2\n",
    "                else:\n",
    "                    i+=1\n",
    "            if low!=i-1:\n",
    "                doc.append(sentence[low:i])\n",
    "    return doc\n",
    "\n",
    "def preprocess(doc, stopwords, stemmer):\n",
    "    #Aplica el preprocesamiento establecido\n",
    "    #Adicionalmente, retorna el documento original sin las filas vacías por el preprocesamiento \n",
    "    doc_preprocesed, doc_reduced = [], []\n",
    "    for original_sentence in doc:\n",
    "        preprocessed_sentence = []\n",
    "        for token in original_sentence:\n",
    "            if stemmer.stem(token) not in stopwords:\n",
    "                preprocessed_sentence.append(stemmer.stem(token))\n",
    "        if len(preprocessed_sentence) and preprocessed_sentence not in doc_preprocesed:\n",
    "            doc_preprocesed.append(preprocessed_sentence)\n",
    "            doc_reduced.append(original_sentence)\n",
    "    return doc_preprocesed, doc_reduced\n",
    "\n",
    "def get_dictionaries(doc):\n",
    "    #Retorna un par de diccionarios que relacionan una frase con un id, y un id con una frase.\n",
    "    sentence2id, id2sentence = {},{}\n",
    "    n_sentences = len(doc)\n",
    "    for i in range(n_sentences):\n",
    "        sentence = ' '.join(doc[i])\n",
    "        if sentence not in sentence2id:\n",
    "            sentence2id[sentence] = i\n",
    "            id2sentence[i] = sentence\n",
    "    return sentence2id, id2sentence\n",
    "\n",
    "def getid2token(token2id):\n",
    "    #Retorna un diccionario de tokens a id, a partir de un diccionario de id a tokens\n",
    "    id2token ={}\n",
    "    for k,v in token2id.items():\n",
    "        id2token[v] = k\n",
    "    return id2token\n",
    "\n",
    "def build_A_Matrix(document, tf_idf, token2id, doc_id):\n",
    "    #Construye la matriz A que recibe el modelo de LSA como entrada\n",
    "    data,row_index,col_index = [],[],[]\n",
    "    tf_idf = tf_idf.toarray()\n",
    "    n,m = len(document), len(token2id)\n",
    "    for i in range(n):\n",
    "        sentence = document[i]\n",
    "        j = 0\n",
    "        for token in sentence:\n",
    "            if token in token2id and tf_idf[doc_id,token2id[token]] != 0:\n",
    "                if (j==0) or (j>0 and token2id[token] not in col_index[-j:]):\n",
    "                    value = tf_idf[doc_id,token2id[token]]\n",
    "                    tf_idf_value = value\n",
    "                    data.append(tf_idf_value)\n",
    "                    row_index.append(i)\n",
    "                    col_index.append(token2id[token])\n",
    "                    j+=1\n",
    "    data = np.array(data)\n",
    "    row_index = np.array(row_index)\n",
    "    col_index = np.array(col_index)\n",
    "    A_matrix = csr_matrix((data,(row_index,col_index)),shape=(n, m),dtype=np.float64)\n",
    "    return A_matrix\n",
    "\n",
    "def generate_summary(lsa, n_sentences, sentence2id):\n",
    "    #Genera un resumen con n_sentences frases\n",
    "    total_sentences = lsa.shape[0]\n",
    "    assert n_sentences < total_sentences\n",
    "    columns = [\"topic {}\".format(i) for i in range(n_sentences)]\n",
    "    df = pd.DataFrame(lsa,columns=columns)\n",
    "    df['sentence'] = sentence2id.keys()\n",
    "    summary = []\n",
    "    for i in range(n_sentences):\n",
    "        df = df.sort_values(by='topic {}'.format(i), ascending = False)\n",
    "        j = 0\n",
    "        while j < total_sentences:\n",
    "            sentence = df.iloc[j]['sentence']\n",
    "            if sentence not in summary:\n",
    "                summary.append(sentence)\n",
    "                j=total_sentences\n",
    "            else:\n",
    "                j+=1\n",
    "    return summary\n",
    "\n",
    "def read_reference(path, filename):\n",
    "    text = PlaintextCorpusReader(path, filename)\n",
    "    text = text.paras()\n",
    "    flat = []\n",
    "    for sentences in text:\n",
    "        for sentence in sentences:\n",
    "            flat_sentence = ' '.join(sentence)\n",
    "            flat.append(flat_sentence)\n",
    "    reference = ' '.join(flat)\n",
    "    return reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1. Cargar datos.\n",
    "En esta fase se cargarán datos obtenidos durante el preprocesamientoy que utilizaremos para obtener el modelo de LSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el modelo de tf-idf obtenido en preprocesamiento.\n",
    "filename = 'tf-idf_model.pkl'\n",
    "tf_idf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Cargar la matriz de tf-idf obtenido en preprocesamiento.\n",
    "filename = 'tf-idf_matrix.pkl'\n",
    "tf_idf_matrix = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Cargar la matriz de tf-idf obtenido en preprocesamiento.\n",
    "filename = 'stopwords.pkl'\n",
    "stopwords = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2. Tokenizar las frases del corpus.\n",
    "En esta fase se tokenizará por el corpus por frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"D:/Documents/Documentos Universidad/Noveno/Proyecto de grado/textos\"\n",
    "stemmer = SpanishStemmer()\n",
    "bolivar = tokenize_sentence(ruta, 'segurosbolivar-privacidad.txt')\n",
    "mozilla = tokenize_sentence(ruta, 'mozilla-privacidad.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 3. Aplicar el preprocesamiento al nuevo corpus.\n",
    "En esta fase se aplicará el preprocesamiento establecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolivar_preprocesado, bolivar = preprocess(bolivar, stopwords, stemmer)\n",
    "mozilla_preprocesado, mozilla = preprocess(mozilla, stopwords, stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 4. Crear diccionarios para relacionar frases e identificadores.\n",
    "Con el fin de obtener un resumen luego de aplicar la técnica de LSA, se necesita relacionar una frase con un identificador único. Esta fase cumple con dicho objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase2id_bolivar, id2frase_bolivar = get_dictionaries(bolivar)\n",
    "frase2id_mozilla, id2frase_mozilla = get_dictionaries(mozilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 5. Construir la matriz de A del Análisis Semántico Latente.\n",
    "Hasta el momento, ya tenemos una lista de frases preprocesadas, ahora lo siguiente que tenemos que hacer es construir una matriz A de NxM, con N frases y M tokens. Para esto nos apoyaremos en el TF-IDF del preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diccionario que relaciona tokens con un identificador único\n",
    "token2id = tf_idf.vocabulary_\n",
    "\n",
    "#Lista de textos dentro del corpus\n",
    "textos = os.listdir(ruta)\n",
    "\n",
    "matriz_A_bolivar = build_A_Matrix(bolivar_preprocesado, tf_idf_matrix, token2id, textos.index('segurosbolivar-privacidad.txt'))\n",
    "matriz_A_mozilla = build_A_Matrix(mozilla_preprocesado, tf_idf_matrix, token2id, textos.index('mozilla-privacidad.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 6. Aplicar la técnica de Análisis Semántico Latente.\n",
    "Una vez construida la matriz A, se utilizará la técnica de LSA para obtener una matriz de MxK, con M frases y K temas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "#Instancia un modelo de LSA\n",
    "lsa_model = TruncatedSVD(n_components=k)\n",
    "\n",
    "#Aplica el LSA a la matriz tf-idf\n",
    "lsa_bolivar = lsa_model.fit_transform(matriz_A_bolivar)\n",
    "lsa_mozilla = lsa_model.fit_transform(matriz_A_mozilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensión de la matriz de Seguros Bolivar\n",
    "lsa_bolivar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensión de la matriz de Mozilla\n",
    "lsa_mozilla.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 7. Generación del resumen\n",
    "A partir del modelo de LSA obtenido en la fase anterior, se genera un resúmen escogiendo una frase por cada tema obtenido dentro del modelo de LSA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAS COMPAÑÍAS han identificado los datos que administran , así como las actividades que desarrollan con dichos datos , en particular su recepción , conservación , disposición para los fines propios del contrato y desarrollo de actividades complementarias referidas a la promoción y el mercadeo de sus productos y servicios , así como los ofrecidos por las Compañías que hacen parte del Grupo Bolívar , al cual éstas pertenecen y así lo han indicado en las Políticas del Tratamiento disponibles para su consulta en la página web www',\n",
       " 'LAS COMPAÑÍAS hacen parte del Grupo Bolívar , que tiene como matriz a Grupo Bolívar S',\n",
       " 'Declaro que , con base en dicho conocimiento , autorizo para que LAS COMPAÑÍAS compartan con dichas empresas y entidades la información personal de contacto y la que sea relevante para las finalidades aquí previstas , que he suministrado',\n",
       " 'Finalidades previstas para los datos obtenidos de candidatos , empleados y proveedores :',\n",
       " 'Solicitar prueba de la autorización otorgada al Responsable del Tratamiento salvo cuando expresamente se exceptúe como requisito para el Tratamiento , de conformidad con lo previsto en el artículo 10 de la presente ley']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen_bolivar = generate_summary(lsa_bolivar,k,frase2id_bolivar)\n",
    "resumen_bolivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Política de Privacidad de Mozilla 9 de septiembre de 2020 ¿ Qué queremos decir con \" informaciones personales \"?',\n",
       " 'Mozilla Corporation Attn : Mozilla - Privacy 2 Harrison St',\n",
       " 'Haz clic aquí para solicitar acceso a los datos personales',\n",
       " 'Eventualmente divulgamos informaciones para mejorar nuestros productos y promover una Internet abierta , pero cuando lo hacemos , excluimos sus informaciones personales e intentamos divulgarlas de forma de minimizar el riesgo de identificación de los usuarios',\n",
       " 'Sus informaciones sólo son divulgadas de esa manera cuando creemos de buena fe que se hace necesario para proteger los derechos , la propiedad o la seguridad del usuario en cuestión , de nuestros otros usuarios , de Mozilla o del público']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen_mozilla = generate_summary(lsa_mozilla,k,frase2id_mozilla)\n",
    "resumen_mozilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar puntajes ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.323450129773832,\n",
       "   'p': 0.3157894736842105,\n",
       "   'r': 0.3314917127071823},\n",
       "  'rouge-2': {'f': 0.059620591208936896,\n",
       "   'p': 0.0582010582010582,\n",
       "   'r': 0.06111111111111111},\n",
       "  'rouge-l': {'f': 0.205607471637261,\n",
       "   'p': 0.20952380952380953,\n",
       "   'r': 0.2018348623853211}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruta_referencia = \"D:/Documents/Documentos Universidad/Noveno/Proyecto de grado/referencias\"\n",
    "\n",
    "referencia_bolivar = read_reference(ruta_referencia, 'segurosbolivar-privacidad.txt')\n",
    "resumen_bolivar = ' '.join(resumen_bolivar)\n",
    "rouge = Rouge()\n",
    "rouge.get_scores(resumen_bolivar, referencia_bolivar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Las', 'compañias', 'pertenecientes', 'al', 'grupo', 'de', 'seguros', 'bolivar', 'almacenaran', 'y', 'manipularan', 'los', 'datos', 'recolectados', 'con', 'el', 'fin', 'de', 'promocionar', 'sus', 'productos', 'y', 'servicios', '.']], [['La', 'información', 'almacenada', 'relativa', 'al', 'estado', 'de', 'salud', 'de', 'los', 'asegurados', 'estará', 'regulada', 'por', 'los', 'estandares', 'especiales', 'de', 'la', 'expedición', 'de', 'polizas', 'de', 'salud', 'o', 'vida', '.']], ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referencia_bolivar.paras()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
